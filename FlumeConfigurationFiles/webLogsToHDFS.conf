# webLogsToHDFS.conf: A single-node Flume configuration
# accumulating web logs to HDFS

# Name the components on this agent
wh.sources = ws
wh.sinks = hdfs
wh.channels = mem

# Describe/configure the source
wh.sources.ws.type = exec
wh.sources.ws.command = tail -F /opt/gen_logs/logs/access.log
wh.sources.ws.port = 44444

# Describe the sink
wh.sinks.hdfs.type = hdfs
wh.sinks.hdfs.hdfs.path = hdfs://sandbox-hdp.hortonworks.com:8020/user/root/flume_demo
wh.sinks.hdfs.hdfs.filePrefix = flume_demo
wh.sinks.hdfs.hdfs.fileSuffix = .txt

wh.sinks.hdfs.hdfs.rollInterval = 120
wh.sinks.hdfs.hdfs.rollSize = 1048576
wh.sinks.hdfs.hdfs.rollCount = 100
wh.sinks.hdfs.hdfs.fileType = DataStream

# Use a channel which buffers events in memory
wh.channels.mem.type = memory
wh.channels.mem.capacity = 1000
wh.channels.mem.transactionCapacity = 100

# Bind the source and sink to the channel
wh.sources.ws.channels = mem
wh.sinks.hdfs.channel = mem

#   $   flume-ng agent --name wh --conf-file /root/aditya/flume_demo/webLogsToHDFS.conf